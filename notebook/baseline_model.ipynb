{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install simplet5\n\n# pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T11:50:00.063283Z","iopub.execute_input":"2023-10-31T11:50:00.063936Z","iopub.status.idle":"2023-10-31T11:50:00.069835Z","shell.execute_reply.started":"2023-10-31T11:50:00.063889Z","shell.execute_reply":"2023-10-31T11:50:00.068481Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install simplet5\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (1032310542.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\nfrom simplet5 import SimpleT5\nfrom tabulate import tabulate\nimport nltk\nfrom datetime import datetime\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:53:35.334004Z","iopub.execute_input":"2023-10-31T11:53:35.334680Z","iopub.status.idle":"2023-10-31T11:53:36.899241Z","shell.execute_reply.started":"2023-10-31T11:53:35.334644Z","shell.execute_reply":"2023-10-31T11:53:36.898379Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pip install simplet5\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:50:28.425158Z","iopub.execute_input":"2023-10-31T11:50:28.425574Z","iopub.status.idle":"2023-10-31T11:51:06.082730Z","shell.execute_reply.started":"2023-10-31T11:50:28.425546Z","shell.execute_reply":"2023-10-31T11:51:06.081457Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting simplet5\n  Downloading simplet5-0.1.4.tar.gz (7.3 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simplet5) (1.23.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from simplet5) (2.0.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simplet5) (0.1.99)\nRequirement already satisfied: torch!=1.8.0,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from simplet5) (2.0.0)\nCollecting transformers==4.16.2 (from simplet5)\n  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hCollecting pytorch-lightning==1.5.10 (from simplet5)\n  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (0.18.3)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (4.66.1)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (6.0)\nRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (2023.9.0)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (2.12.3)\nRequirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (1.1.1)\nCollecting pyDeprecate==0.3.1 (from pytorch-lightning==1.5.10->simplet5)\n  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (21.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (4.6.3)\nCollecting setuptools==59.5.0 (from pytorch-lightning==1.5.10->simplet5)\n  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (2.31.0)\nCollecting sacremoses (from transformers==4.16.2->simplet5)\n  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (0.13.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->simplet5) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->simplet5) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->simplet5) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->simplet5) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simplet5) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simplet5) (2023.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (3.8.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->pytorch-lightning==1.5.10->simplet5) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->simplet5) (1.16.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (3.4.3)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (2.3.7)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.40.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (2023.7.22)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.4.1->pytorch-lightning==1.5.10->simplet5) (0.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.8.0,>=1.7.0->simplet5) (2.1.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.16.2->simplet5) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.16.2->simplet5) (1.3.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.8.0,>=1.7.0->simplet5) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (1.3.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.3.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (3.2.2)\nBuilding wheels for collected packages: simplet5\n  Building wheel for simplet5 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for simplet5: filename=simplet5-0.1.4-py3-none-any.whl size=6857 sha256=ca28b9ac6232f4068de6f574f7d23fc2ada009be9f67b3bebafe46dfffed1fac\n  Stored in directory: /root/.cache/pip/wheels/b4/7d/af/743765400878438a7593f13f89fdf4004dcde0f2a8e6cb6684\nSuccessfully built simplet5\nInstalling collected packages: setuptools, sacremoses, pyDeprecate, transformers, pytorch-lightning, simplet5\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 68.0.0\n    Uninstalling setuptools-68.0.0:\n      Successfully uninstalled setuptools-68.0.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.0.8\n    Uninstalling pytorch-lightning-2.0.8:\n      Successfully uninstalled pytorch-lightning-2.0.8\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nconda 23.7.3 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\nopentelemetry-api 1.18.0 requires importlib-metadata~=6.0.0, but you have importlib-metadata 6.7.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyDeprecate-0.3.1 pytorch-lightning-1.5.10 sacremoses-0.1.1 setuptools-59.5.0 simplet5-0.1.4 transformers-4.16.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:51:06.084897Z","iopub.execute_input":"2023-10-31T11:51:06.085274Z","iopub.status.idle":"2023-10-31T11:51:17.776365Z","shell.execute_reply.started":"2023-10-31T11:51:06.085235Z","shell.execute_reply":"2023-10-31T11:51:17.775231Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import datasets\nanswersummData = datasets.load_dataset(\"alexfabbri/answersumm\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:53:48.332136Z","iopub.execute_input":"2023-10-31T11:53:48.332781Z","iopub.status.idle":"2023-10-31T11:53:55.604745Z","shell.execute_reply.started":"2023-10-31T11:53:48.332751Z","shell.execute_reply":"2023-10-31T11:53:55.603799Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/alexfabbri--answersumm to /root/.cache/huggingface/datasets/json/alexfabbri--answersumm-18f7fb4735693092/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"223b9be66ab74ec2ab14c68fbc4cf9c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/24.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c4812711fc34bd581bb5cd442d7b414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/8.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52a59eb2cbe744b48da02506822cc97f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.43M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ac6ae3a4d04447a2d585168d9d2fbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"841a1b5cf8c9413aa1bac67455b468d4"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/alexfabbri--answersumm-18f7fb4735693092/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a84bdfa9dd24355a6f1046be7ead9a3"}},"metadata":{}}]},{"cell_type":"code","source":"answersummDataTest = answersummData[\"test\"]\nanswersummDataTrain = answersummData[\"train\"]\nanswersummDataVal = answersummData[\"validation\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:53:55.606861Z","iopub.execute_input":"2023-10-31T11:53:55.607384Z","iopub.status.idle":"2023-10-31T11:53:55.612153Z","shell.execute_reply.started":"2023-10-31T11:53:55.607348Z","shell.execute_reply":"2023-10-31T11:53:55.611187Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"answersummDataTest","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:53:55.613316Z","iopub.execute_input":"2023-10-31T11:53:55.613879Z","iopub.status.idle":"2023-10-31T11:53:55.623867Z","shell.execute_reply.started":"2023-10-31T11:53:55.613853Z","shell.execute_reply":"2023-10-31T11:53:55.622870Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['answers', 'question', 'example_id', 'summaries', 'mismatch_info', 'annotator_id', 'cluster_summaries'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"answersummDataTest[2]['question']['title']","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:53:55.626681Z","iopub.execute_input":"2023-10-31T11:53:55.627154Z","iopub.status.idle":"2023-10-31T11:53:55.636551Z","shell.execute_reply.started":"2023-10-31T11:53:55.627108Z","shell.execute_reply":"2023-10-31T11:53:55.635669Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'Buying vs catching a horse in Red Dead Redemption'"},"metadata":{}}]},{"cell_type":"code","source":"def flatten(example):\n  answers = example[\"answers\"]\n#  print(answers[0])\n  allanswers = \"\"\n  for answer in answers:\n    lines = answer[\"sents\"]\n    for line in lines:\n      allanswers = allanswers + line[\"text\"] + \" \"\n    \n  return {\n      \"title\": example[\"question\"][\"title\"],\n      \"question\": example[\"question\"][\"question\"],\n      \"allanswers\": allanswers,\n      \"clustersummary\": \" \".join(example[\"cluster_summaries\"][0]),\n      \"firstsummary\": example[\"summaries\"][0][0],\n      \"secondsummary\": example[\"summaries\"][0][1],\n      \"question+clustersumm\": example[\"question\"][\"question\"] + \" \" + \" \".join(example[\"cluster_summaries\"][0]),\n      \"question+allanswers\": example[\"question\"][\"question\"] + \" \" + allanswers\n      }","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:53:55.637803Z","iopub.execute_input":"2023-10-31T11:53:55.638194Z","iopub.status.idle":"2023-10-31T11:53:55.646658Z","shell.execute_reply.started":"2023-10-31T11:53:55.638161Z","shell.execute_reply":"2023-10-31T11:53:55.645540Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data_txt = answersummDataTrain.map(flatten, remove_columns=['answers', 'question', 'example_id', 'summaries', 'mismatch_info', 'annotator_id', 'cluster_summaries'])\nval_data_txt = answersummDataVal.map(flatten, remove_columns=['answers', 'question', 'example_id', 'summaries', 'mismatch_info', 'annotator_id', 'cluster_summaries'])\ntest_data_txt = answersummDataTest.map(flatten, remove_columns=['answers', 'question', 'example_id', 'summaries', 'mismatch_info', 'annotator_id', 'cluster_summaries'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:53:55.648027Z","iopub.execute_input":"2023-10-31T11:53:55.648363Z","iopub.status.idle":"2023-10-31T11:54:02.583047Z","shell.execute_reply.started":"2023-10-31T11:53:55.648336Z","shell.execute_reply":"2023-10-31T11:54:02.581978Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2783 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe97f3dec0c4ba7adcec559f01d6175"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"429a3a4ca24541ae9744ec1db0bf1f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c80c72b7f7b41d2882ef7e9905bf561"}},"metadata":{}}]},{"cell_type":"code","source":"train_data_txt","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:02.584475Z","iopub.execute_input":"2023-10-31T11:54:02.584864Z","iopub.status.idle":"2023-10-31T11:54:02.591602Z","shell.execute_reply.started":"2023-10-31T11:54:02.584829Z","shell.execute_reply":"2023-10-31T11:54:02.590626Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'title', 'allanswers', 'clustersummary', 'firstsummary', 'secondsummary', 'question+clustersumm', 'question+allanswers'],\n    num_rows: 2783\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_data_txt.column_names","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:02.593133Z","iopub.execute_input":"2023-10-31T11:54:02.593816Z","iopub.status.idle":"2023-10-31T11:54:02.630551Z","shell.execute_reply.started":"2023-10-31T11:54:02.593781Z","shell.execute_reply":"2023-10-31T11:54:02.629597Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['question',\n 'title',\n 'allanswers',\n 'clustersummary',\n 'firstsummary',\n 'secondsummary',\n 'question+clustersumm',\n 'question+allanswers']"},"metadata":{}}]},{"cell_type":"code","source":"def average_token_len(data):\n  sum = 0\n  for i in range(len(data)):\n    sum += len(data[i].split())\n  return sum/len(data)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:02.631798Z","iopub.execute_input":"2023-10-31T11:54:02.632834Z","iopub.status.idle":"2023-10-31T11:54:02.640944Z","shell.execute_reply.started":"2023-10-31T11:54:02.632807Z","shell.execute_reply":"2023-10-31T11:54:02.640036Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(average_token_len(train_data_txt['question']))\nprint(average_token_len(train_data_txt['allanswers']))\nprint(average_token_len(train_data_txt['firstsummary']))\nprint(average_token_len(train_data_txt['secondsummary']))\nprint(average_token_len(train_data_txt['clustersummary']))\nprint(average_token_len(train_data_txt['question+allanswers']))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:02.645731Z","iopub.execute_input":"2023-10-31T11:54:02.646044Z","iopub.status.idle":"2023-10-31T11:54:02.989928Z","shell.execute_reply.started":"2023-10-31T11:54:02.646020Z","shell.execute_reply":"2023-10-31T11:54:02.988964Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"52.54293927416457\n685.0416816385195\n48.361480416816384\n41.03305785123967\n50.11749910168883\n737.5846209126842\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model-Bart trained on X-Sum\n\n# model_name = \"sshleifer/distilbart-xsum-12-3\"\n# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n# tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:02.991113Z","iopub.execute_input":"2023-10-31T11:54:02.991404Z","iopub.status.idle":"2023-10-31T11:54:02.996016Z","shell.execute_reply.started":"2023-10-31T11:54:02.991379Z","shell.execute_reply":"2023-10-31T11:54:02.994808Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Model T-5\nmodel = T5ForConditionalGeneration.from_pretrained('t5-small')\ntokenizer = T5Tokenizer.from_pretrained('t5-base')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:02.997477Z","iopub.execute_input":"2023-10-31T11:54:02.997790Z","iopub.status.idle":"2023-10-31T11:54:07.401091Z","shell.execute_reply.started":"2023-10-31T11:54:02.997766Z","shell.execute_reply":"2023-10-31T11:54:07.400344Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d12f34a42e498da3dcda62a97a1d0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a6832c78b545e3af164506f013da62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"691c17be32fd4d11874271fef034b61b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a04fc6ddfb4b88ae69905d28ca8b25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb7080bfb8d42fb9c69e11373da59fb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:220: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  return len(token_ids_0 + eos) * [0]\nYou are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}]},{"cell_type":"code","source":"val_data_txt[0][\"question+clustersumm\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:07.402298Z","iopub.execute_input":"2023-10-31T11:54:07.403013Z","iopub.status.idle":"2023-10-31T11:54:07.409278Z","shell.execute_reply.started":"2023-10-31T11:54:07.402978Z","shell.execute_reply":"2023-10-31T11:54:07.408350Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"\"Assume that someone (friend, family) asks you to format his/her CV. They typically might want to apply to a job where text processing etc. is not one of the key requirements and they ask you to do it in order to have a nice result and/or to win time, although they could probably do it themselves in Word.  Can it be negative for them? Imagine for instance that the interviewer asks them how they made such a nice CV. It is generally agreed that it's perfectly acceptable to help someone format their CV and it's unlikely to have any negative repercussions for them.\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"### **Parameters**\"\"\"\n\nencoder_max_length = 512\ndecoder_max_length = 128\ninput = \"clustersummary\"\noutput = \"secondsummary\"\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"results\",\n    num_train_epochs=5,  # demo\n    do_train=True,\n    do_eval=True,\n    per_device_train_batch_size=2,  # demo\n    per_device_eval_batch_size=2,\n    # learning_rate=3e-05,\n    warmup_steps=100,\n    weight_decay=0.1,\n    label_smoothing_factor=0.1,\n    predict_with_generate=True,\n    logging_dir=\"logs\",\n    logging_steps=50,\n    save_total_limit=3,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:07.410434Z","iopub.execute_input":"2023-10-31T11:54:07.410742Z","iopub.status.idle":"2023-10-31T11:54:07.491617Z","shell.execute_reply.started":"2023-10-31T11:54:07.410718Z","shell.execute_reply":"2023-10-31T11:54:07.490687Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n    source, target = batch[input], batch[output]\n    source_tokenized = tokenizer(\n        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n    )\n    target_tokenized = tokenizer(\n        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n    )\n\n    batch = {k: v for k, v in source_tokenized.items()}\n    # Ignore padding in the loss\n    batch[\"labels\"] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in l]\n        for l in target_tokenized[\"input_ids\"]\n    ]\n    return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:07.492847Z","iopub.execute_input":"2023-10-31T11:54:07.493148Z","iopub.status.idle":"2023-10-31T11:54:07.499726Z","shell.execute_reply.started":"2023-10-31T11:54:07.493121Z","shell.execute_reply":"2023-10-31T11:54:07.498889Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_data = train_data_txt.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=train_data_txt.column_names,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:07.500852Z","iopub.execute_input":"2023-10-31T11:54:07.501144Z","iopub.status.idle":"2023-10-31T11:54:11.681960Z","shell.execute_reply.started":"2023-10-31T11:54:07.501120Z","shell.execute_reply":"2023-10-31T11:54:11.680947Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d56ea8fbaf4feabf6e264f77080005"}},"metadata":{}}]},{"cell_type":"code","source":"val_data = val_data_txt.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=val_data_txt.column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:11.683466Z","iopub.execute_input":"2023-10-31T11:54:11.683756Z","iopub.status.idle":"2023-10-31T11:54:12.428369Z","shell.execute_reply.started":"2023-10-31T11:54:11.683731Z","shell.execute_reply":"2023-10-31T11:54:12.427297Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f662a5396ed541e391a544eba6675324"}},"metadata":{}}]},{"cell_type":"code","source":"test_data = test_data_txt.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=test_data_txt.column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:12.429506Z","iopub.execute_input":"2023-10-31T11:54:12.429794Z","iopub.status.idle":"2023-10-31T11:54:13.826711Z","shell.execute_reply.started":"2023-10-31T11:54:12.429763Z","shell.execute_reply":"2023-10-31T11:54:13.825711Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b208f955e34940f0a896e88a36e64aa7"}},"metadata":{}}]},{"cell_type":"code","source":"type(train_data_txt)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:13.828198Z","iopub.execute_input":"2023-10-31T11:54:13.828640Z","iopub.status.idle":"2023-10-31T11:54:13.836809Z","shell.execute_reply.started":"2023-10-31T11:54:13.828602Z","shell.execute_reply":"2023-10-31T11:54:13.834972Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"datasets.arrow_dataset.Dataset"},"metadata":{}}]},{"cell_type":"code","source":"pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:13.838096Z","iopub.execute_input":"2023-10-31T11:54:13.838447Z","iopub.status.idle":"2023-10-31T11:54:27.755152Z","shell.execute_reply.started":"2023-10-31T11:54:13.838412Z","shell.execute_reply":"2023-10-31T11:54:27.753874Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.23.5)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=891f2ab0d39814ea1fbd2df1deee84ad2dcc37fea2a10cbbbcba80235a5c7548\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"#METRICS\nnltk.download(\"punkt\", quiet=True)\n\nmetric = datasets.load_metric(\"rouge\")\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n\n    return preds, labels","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:27.757171Z","iopub.execute_input":"2023-10-31T11:54:27.758117Z","iopub.status.idle":"2023-10-31T11:54:28.910707Z","shell.execute_reply.started":"2023-10-31T11:54:27.758072Z","shell.execute_reply":"2023-10-31T11:54:28.909692Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74c8eb6fb79e48739155c0cfb075a9f4"}},"metadata":{}}]},{"cell_type":"code","source":"pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:28.911844Z","iopub.execute_input":"2023-10-31T11:54:28.912162Z","iopub.status.idle":"2023-10-31T11:54:40.618042Z","shell.execute_reply.started":"2023-10-31T11:54:28.912136Z","shell.execute_reply":"2023-10-31T11:54:40.616827Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:40.619675Z","iopub.execute_input":"2023-10-31T11:54:40.620011Z","iopub.status.idle":"2023-10-31T11:54:52.331434Z","shell.execute_reply.started":"2023-10-31T11:54:40.619981Z","shell.execute_reply":"2023-10-31T11:54:52.330165Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.9)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.5.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract a few results from ROUGE\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n\n    prediction_lens = [\n        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n    ]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:52.333190Z","iopub.execute_input":"2023-10-31T11:54:52.333531Z","iopub.status.idle":"2023-10-31T11:54:52.343759Z","shell.execute_reply.started":"2023-10-31T11:54:52.333499Z","shell.execute_reply":"2023-10-31T11:54:52.342558Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:52.345303Z","iopub.execute_input":"2023-10-31T11:54:52.345660Z","iopub.status.idle":"2023-10-31T11:54:52.370602Z","shell.execute_reply.started":"2023-10-31T11:54:52.345627Z","shell.execute_reply":"2023-10-31T11:54:52.369633Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"data_collator","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:52.371859Z","iopub.execute_input":"2023-10-31T11:54:52.372182Z","iopub.status.idle":"2023-10-31T11:54:52.387237Z","shell.execute_reply.started":"2023-10-31T11:54:52.372156Z","shell.execute_reply":"2023-10-31T11:54:52.385854Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DataCollatorForSeq2Seq(tokenizer=T5Tokenizer(name_or_path='t5-base', vocab_size=32100, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True), model=T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n), padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"},"metadata":{}}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_data,\n    eval_dataset=val_data,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:52.390842Z","iopub.execute_input":"2023-10-31T11:54:52.391201Z","iopub.status.idle":"2023-10-31T11:54:58.269543Z","shell.execute_reply.started":"2023-10-31T11:54:52.391173Z","shell.execute_reply":"2023-10-31T11:54:58.268663Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_NOTEBOOK_NAME\"] = 't5model'","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:58.274384Z","iopub.execute_input":"2023-10-31T11:54:58.275012Z","iopub.status.idle":"2023-10-31T11:54:58.279421Z","shell.execute_reply.started":"2023-10-31T11:54:58.274981Z","shell.execute_reply":"2023-10-31T11:54:58.278488Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#EVALUATE BEFORE FINE TUNING\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:54:58.280873Z","iopub.execute_input":"2023-10-31T11:54:58.281262Z","iopub.status.idle":"2023-10-31T11:57:05.152912Z","shell.execute_reply.started":"2023-10-31T11:54:58.281172Z","shell.execute_reply":"2023-10-31T11:57:05.151976Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 13:56]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find t5model.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 4.004023551940918,\n 'eval_rouge1': 31.6882,\n 'eval_rouge2': 21.0228,\n 'eval_rougeL': 28.4811,\n 'eval_rougeLsum': 29.9327,\n 'eval_gen_len': 17.736,\n 'eval_runtime': 94.5079,\n 'eval_samples_per_second': 5.291,\n 'eval_steps_per_second': 1.323}"},"metadata":{}}]},{"cell_type":"code","source":"#TRAIN THE MODEL\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:57:05.154422Z","iopub.execute_input":"2023-10-31T11:57:05.155004Z","iopub.status.idle":"2023-10-31T12:08:24.205947Z","shell.execute_reply.started":"2023-10-31T11:57:05.154974Z","shell.execute_reply":"2023-10-31T12:08:24.204886Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3480' max='3480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3480/3480 11:18, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>3.631700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>3.380300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>3.095900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.965100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>2.778800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.774300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>2.855900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.777800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>2.849000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>2.794200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>2.674100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.682400</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>2.721800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>2.751300</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>2.689500</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.720000</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>2.690100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>2.620700</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>2.708300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.750200</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>2.500500</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>2.699400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>2.569800</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>2.569800</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>2.687500</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>2.520800</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>2.635400</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>2.645400</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>2.644500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.517700</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>2.693500</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>2.695800</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>2.602100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>2.678800</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>2.613000</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>2.611500</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>2.520600</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>2.573200</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>2.566300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.553800</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>2.475300</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>2.497700</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>2.671700</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>2.620300</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>2.581300</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>2.532700</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>2.526300</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>2.467900</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>2.441300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.616600</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>2.550900</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>2.583000</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>2.606100</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>2.553900</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>2.717900</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>2.520000</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>2.429900</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>2.497400</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>2.501400</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.603300</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>2.614200</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>2.535800</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>2.603400</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>2.487900</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>2.682500</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>2.488100</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>2.732700</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>2.531800</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>2.508200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3480, training_loss=2.654366580919288, metrics={'train_runtime': 678.7076, 'train_samples_per_second': 20.502, 'train_steps_per_second': 5.127, 'total_flos': 1883281167482880.0, 'train_loss': 2.654366580919288, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"\n#EVALUATE AFTER FINE TUNING\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:08:24.207561Z","iopub.execute_input":"2023-10-31T12:08:24.207967Z","iopub.status.idle":"2023-10-31T12:09:51.649620Z","shell.execute_reply.started":"2023-10-31T12:08:24.207929Z","shell.execute_reply":"2023-10-31T12:09:51.648298Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.8057451248168945,\n 'eval_rouge1': 46.6567,\n 'eval_rouge2': 34.9836,\n 'eval_rougeL': 42.4541,\n 'eval_rougeLsum': 44.1899,\n 'eval_gen_len': 18.352,\n 'eval_runtime': 87.4265,\n 'eval_samples_per_second': 5.719,\n 'eval_steps_per_second': 1.43,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"code","source":"#Generate summaries from the fine-tuned model and compare them with those generated from the original, pre-trained one.\ndef generate_summary(test_samples, model):\n    inputs = tokenizer(\n        test_samples['clustersummary'],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=encoder_max_length,\n        return_tensors=\"pt\",\n    )\n    input_ids = inputs.input_ids.to(model.device)\n    attention_mask = inputs.attention_mask.to(model.device)\n    outputs = model.generate(input_ids, attention_mask=attention_mask)\n    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return outputs, output_str","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:10:05.211401Z","iopub.execute_input":"2023-10-31T12:10:05.211868Z","iopub.status.idle":"2023-10-31T12:10:05.219876Z","shell.execute_reply.started":"2023-10-31T12:10:05.211838Z","shell.execute_reply":"2023-10-31T12:10:05.218966Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade transformers\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:10:08.076624Z","iopub.execute_input":"2023-10-31T12:10:08.077010Z","iopub.status.idle":"2023-10-31T12:10:27.514715Z","shell.execute_reply.started":"2023-10-31T12:10:08.076979Z","shell.execute_reply":"2023-10-31T12:10:27.513410Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.16.2)\nCollecting transformers\n  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nCollecting tokenizers<0.15,>=0.14 (from transformers)\n  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.13.3\n    Uninstalling tokenizers-0.13.3:\n      Successfully uninstalled tokenizers-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.16.2\n    Uninstalling transformers-4.16.2:\n      Successfully uninstalled transformers-4.16.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsimplet5 0.1.4 requires transformers==4.16.2, but you have transformers 4.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.14.1 transformers-4.34.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"#model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\nmodel_before_tuning = T5ForConditionalGeneration.from_pretrained('t5-small')\ntest_samples = val_data_txt.select(range(5))\nmodel_after_training = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-xsum-12-3\")\nmodel_before_tuning = T5ForConditionalGeneration.from_pretrained('t5-small')\nsummaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\nsummaries_after_tuning = generate_summary(test_samples, model)[1]\nsummaries_after_training = generate_summary(test_samples, model_after_training)[1]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:11:31.154648Z","iopub.execute_input":"2023-10-31T12:11:31.155028Z","iopub.status.idle":"2023-10-31T12:11:57.254402Z","shell.execute_reply.started":"2023-10-31T12:11:31.155000Z","shell.execute_reply":"2023-10-31T12:11:57.253212Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a0914746c9d401c8d43e373b55a487b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/716M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3f721845f84d6ba9a1faeebd50296f"}},"metadata":{}}]},{"cell_type":"code","source":"summaries_before_tuning","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:13:38.469699Z","iopub.execute_input":"2023-10-31T12:13:38.470665Z","iopub.status.idle":"2023-10-31T12:13:38.478249Z","shell.execute_reply.started":"2023-10-31T12:13:38.470631Z","shell.execute_reply":"2023-10-31T12:13:38.477193Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"[\"and CV and it's unlikely to have negative repercussions on them.\",\n 'that this is a bad decision.',\n '.',\n '.........',\n '. your desk so that there is no space behind you to stand. You could place']"},"metadata":{}}]},{"cell_type":"code","source":"summaries_after_tuning","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:13:50.251180Z","iopub.execute_input":"2023-10-31T12:13:50.251784Z","iopub.status.idle":"2023-10-31T12:13:50.258705Z","shell.execute_reply.started":"2023-10-31T12:13:50.251755Z","shell.execute_reply":"2023-10-31T12:13:50.257743Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[\"It is generally agreed that it's perfectly acceptable to help someone format their CV and it'\",\n 'It is generally agreed that this is a bad decision. The only situation that this could be',\n 'The general consensus is that, whilst this lack of motivation is understandable, it is',\n 'The best answer to this question would be to simply explain how your approached the problem, what potential',\n \"You could consider angling your desk to make it seem more 'open' to visitors\"]"},"metadata":{}}]},{"cell_type":"code","source":"summaries_after_training","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:13:57.278459Z","iopub.execute_input":"2023-10-31T12:13:57.279448Z","iopub.status.idle":"2023-10-31T12:13:57.286666Z","shell.execute_reply.started":"2023-10-31T12:13:57.279414Z","shell.execute_reply":"2023-10-31T12:13:57.285580Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"[\"’ compte generally agreed that it's perfectly acceptable to help to helpre.T alreadya deep beBN have itdX\",\n 'de applicationa. were the only way of were the water way ofensuring that your application arrived on time. applicationa time. wayX',\n 'at this lack of motivation is understandable, it is not ethical to not work your notice period after after after at this Gabsignreing. Some people may considerX',\n 'ul best answer to heater answer tot this question. besta. best answer. question. simply explain how your approached the problem, what potential solutions you identified and how identified and you chose the one to pursue. This is not generall considered considered and how you choseX',\n 'dance considerangling your desk to makeangling. You could place obstacles on the floor, such as plants or Atmosphäreaa backpack to discourage, you could alwaysX']"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(10):\n  print(val_data_txt['secondsummary'][i])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:14:15.165352Z","iopub.execute_input":"2023-10-31T12:14:15.166156Z","iopub.status.idle":"2023-10-31T12:14:15.192812Z","shell.execute_reply.started":"2023-10-31T12:14:15.166119Z","shell.execute_reply":"2023-10-31T12:14:15.191728Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"It is generally agreed that it's perfectly acceptable to help someone format their CV and it's unlikely to have any negative repercussions for them.\nThe general consensus is that this is a bad decision unless it is the absolute only way of ensuring that your application arrives on time.\nThe general consensus is that, whilst this lack of motivation is understandable, this is not ethical behaviour and some people would even consider it to be illegal as a breach of contract.\nThis sort of question is not generally considered to be a trick question. The most appropriate answer would be simply to describe how you approached a past problem, what solutions you identified and how you chose the one to pursue.\nThere are a number of options available, including orientating your desk so that there is no need to move behind you or placing objects on the floor, like plants, to obstruct an easy path behind your desk. If people need to see your screen, you could mount it on a rotating arm, and finally, if you really want to discourage any unusual behaviour, you could mount a visible camera in your office cubicle.\nThere are websites which offer test materials which might help you assess an applicant's skills. However, the best option is likely to be to find an expert, whether a friend or a consultant, who can help you assess an applicant's skillset.\nWithout knowing exactly what the meeting is about, the most important thing will be to listen and pay close attention both before and during the meeting. However, you will want to prepare for the worst, just in case, and this means both mentally and physically. You may want to make sure that your belongs are ready to go should you have to leave. But despite this potential risk, you should aim to stay calm and not stress too much, including during the meeting.\nThe best advice in this situation would probably be to do nothing and call the other person's bluff.\nThe exact answer to this question may depend on the country you are in. However, many people would consider this to be unusual and, in some countries, it may even be illegal.\nThe exact response to this situation will depend on numerous factors, but, given the exceptional nature of present circumstances, most people would say that you should allow home working.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}